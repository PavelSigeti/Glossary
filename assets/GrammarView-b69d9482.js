import{_ as e,o as a,c as t,a as s,w as i,H as o,F as d,f as n,d as r}from"./index-de45eabf.js";const c=n('<main data-v-3142bb66><div class="container" data-v-3142bb66><div class="item" data-v-3142bb66><div class="item-title" data-v-3142bb66>Passive Voice</div><div class="sentence" data-v-3142bb66>Web robots or web crawlers <u data-v-3142bb66>are used</u> to index web pages to be used in their page ranking process.</div><div class="sentence" data-v-3142bb66>Honeypot <u data-v-3142bb66>is represented</u> as an invisible link or a vulnerable web page.</div><div class="sentence" data-v-3142bb66>Web robots, also known as spiders, crawlers, walkers, wanderers, and harvesters, are computer programs that <u data-v-3142bb66>are designed</u> to travel across the Internet and collect data from web pages autonomously.</div><div class="sentence" data-v-3142bb66>Malicious robots <u data-v-3142bb66>are often characterized</u> by activities that violate the robots.txt file, collect sensitive information, and consume large amounts of bandwidth to stage Distributed Denial of Service (DDoS) attacks.</div></div><div class="item" data-v-3142bb66><div class="item-title" data-v-3142bb66>&#39;It + is + adjective + that-clause&#39; construction</div><div class="sentence" data-v-3142bb66>It is important that web robot detection techniques be continually developed to keep pace with evolving technologies.</div></div></div></main>',1),b={__name:"GrammarView",setup(v){return(l,u)=>(a(),t(d,null,[s(o,null,{default:i(()=>[r("Grammar")]),_:1}),c],64))}},_=e(b,[["__scopeId","data-v-3142bb66"]]);export{_ as default};
